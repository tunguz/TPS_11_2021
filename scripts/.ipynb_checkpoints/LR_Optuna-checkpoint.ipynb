{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.8/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('../../TPS_2021/input/tabular-playground-series-nov-2021/xgtrain.csv')\n",
    "test_x = pd.read_csv('../../TPS_2021/input/tabular-playground-series-nov-2021/xgval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_x['target']\n",
    "train_x = train_x[train_x.columns.difference(['target'])]\n",
    "\n",
    "test_y = test_x['target']\n",
    "test_x = test_x[test_x.columns.difference(['target'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.282090</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>0.507483</td>\n",
       "      <td>-1.102086</td>\n",
       "      <td>0.250591</td>\n",
       "      <td>-0.779308</td>\n",
       "      <td>-1.122699</td>\n",
       "      <td>-0.646795</td>\n",
       "      <td>-1.073323</td>\n",
       "      <td>-0.166890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960254</td>\n",
       "      <td>0.412144</td>\n",
       "      <td>0.311905</td>\n",
       "      <td>0.893324</td>\n",
       "      <td>0.350115</td>\n",
       "      <td>0.593789</td>\n",
       "      <td>0.568979</td>\n",
       "      <td>0.491097</td>\n",
       "      <td>0.149572</td>\n",
       "      <td>-0.602242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.194928</td>\n",
       "      <td>0.215904</td>\n",
       "      <td>-0.141631</td>\n",
       "      <td>0.325356</td>\n",
       "      <td>0.368926</td>\n",
       "      <td>0.217543</td>\n",
       "      <td>-0.016966</td>\n",
       "      <td>-0.019834</td>\n",
       "      <td>-0.167348</td>\n",
       "      <td>0.977802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063751</td>\n",
       "      <td>0.614283</td>\n",
       "      <td>-0.029259</td>\n",
       "      <td>0.326728</td>\n",
       "      <td>0.048380</td>\n",
       "      <td>0.348578</td>\n",
       "      <td>0.196977</td>\n",
       "      <td>0.238384</td>\n",
       "      <td>-0.509677</td>\n",
       "      <td>-0.641434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.736800</td>\n",
       "      <td>-0.884513</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>-0.513603</td>\n",
       "      <td>0.355739</td>\n",
       "      <td>0.424652</td>\n",
       "      <td>0.887490</td>\n",
       "      <td>0.910991</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>0.264538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125968</td>\n",
       "      <td>0.612566</td>\n",
       "      <td>0.172555</td>\n",
       "      <td>0.745312</td>\n",
       "      <td>-1.303931</td>\n",
       "      <td>-0.168392</td>\n",
       "      <td>0.112347</td>\n",
       "      <td>-0.634083</td>\n",
       "      <td>-0.703400</td>\n",
       "      <td>0.719828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.046304</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.815991</td>\n",
       "      <td>0.024154</td>\n",
       "      <td>-0.854849</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.664803</td>\n",
       "      <td>0.743505</td>\n",
       "      <td>-0.687400</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426436</td>\n",
       "      <td>0.804224</td>\n",
       "      <td>0.917206</td>\n",
       "      <td>0.554493</td>\n",
       "      <td>-0.424074</td>\n",
       "      <td>-0.091703</td>\n",
       "      <td>-0.145119</td>\n",
       "      <td>0.433999</td>\n",
       "      <td>0.821814</td>\n",
       "      <td>-2.553369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.567570</td>\n",
       "      <td>0.410281</td>\n",
       "      <td>-0.136002</td>\n",
       "      <td>-0.600729</td>\n",
       "      <td>0.285202</td>\n",
       "      <td>-0.790657</td>\n",
       "      <td>0.091353</td>\n",
       "      <td>0.505161</td>\n",
       "      <td>-0.481196</td>\n",
       "      <td>0.293772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499046</td>\n",
       "      <td>-0.930463</td>\n",
       "      <td>-0.441759</td>\n",
       "      <td>-0.264764</td>\n",
       "      <td>-2.489730</td>\n",
       "      <td>-0.964765</td>\n",
       "      <td>0.960865</td>\n",
       "      <td>-0.858346</td>\n",
       "      <td>-0.540128</td>\n",
       "      <td>-1.347045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1       f10       f11       f12       f13       f14  \\\n",
       "0 -0.282090 -0.011114  0.507483 -1.102086  0.250591 -0.779308 -1.122699   \n",
       "1 -0.194928  0.215904 -0.141631  0.325356  0.368926  0.217543 -0.016966   \n",
       "2  5.736800 -0.884513  0.519139 -0.513603  0.355739  0.424652  0.887490   \n",
       "3 -0.046304  0.018744  0.815991  0.024154 -0.854849  0.381389  0.664803   \n",
       "4  1.567570  0.410281 -0.136002 -0.600729  0.285202 -0.790657  0.091353   \n",
       "\n",
       "        f15       f16       f17  ...       f90       f91       f92       f93  \\\n",
       "0 -0.646795 -1.073323 -0.166890  ... -0.960254  0.412144  0.311905  0.893324   \n",
       "1 -0.019834 -0.167348  0.977802  ...  0.063751  0.614283 -0.029259  0.326728   \n",
       "2  0.910991  0.369959  0.264538  ... -0.125968  0.612566  0.172555  0.745312   \n",
       "3  0.743505 -0.687400  0.046986  ...  0.426436  0.804224  0.917206  0.554493   \n",
       "4  0.505161 -0.481196  0.293772  ... -0.499046 -0.930463 -0.441759 -0.264764   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0  0.350115  0.593789  0.568979  0.491097  0.149572 -0.602242  \n",
       "1  0.048380  0.348578  0.196977  0.238384 -0.509677 -0.641434  \n",
       "2 -1.303931 -0.168392  0.112347 -0.634083 -0.703400  0.719828  \n",
       "3 -0.424074 -0.091703 -0.145119  0.433999  0.821814 -2.553369  \n",
       "4 -2.489730 -0.964765  0.960865 -0.858346 -0.540128 -1.347045  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 0.000000001, 1.0),\n",
    "        'random_state': 0,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict_proba(test_x)[:,1]\n",
    "    auc = roc_auc_score(test_y, predictions)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-15 08:21:49,637]\u001b[0m A new study created in memory with name: no-name-32c04526-8c3a-4991-832f-3d684988a42d\u001b[0m\n",
      "\u001b[32m[I 2021-12-15 08:22:25,876]\u001b[0m Trial 0 finished with value: 0.750663777763448 and parameters: {'C': 0.40272193880083407}. Best is trial 0 with value: 0.750663777763448.\u001b[0m\n",
      "\u001b[32m[I 2021-12-15 08:23:02,286]\u001b[0m Trial 1 finished with value: 0.7506639105698588 and parameters: {'C': 0.15281436487084918}. Best is trial 1 with value: 0.7506639105698588.\u001b[0m\n",
      "\u001b[32m[I 2021-12-15 08:23:39,037]\u001b[0m Trial 2 finished with value: 0.7506638736174474 and parameters: {'C': 0.20607762586010325}. Best is trial 1 with value: 0.7506639105698588.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 3\n",
      "Best trial: {'C': 0.15281436487084918}\n",
      "CPU times: user 1.42 s, sys: 3.67 s, total: 5.08 s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.15281436487084918}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
